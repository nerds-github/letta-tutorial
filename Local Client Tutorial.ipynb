{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35db4c52-06e3-4c17-ab95-5c1bafe55c9a",
   "metadata": {},
   "source": [
    "# Introduction to Letta using the `LocalClient` \n",
    "This notebook is a tutorial on how to use Letta's `LocalClient`. Unlike the `RESTClient` which connects to a running agents service, the `LocalClient` will run agents on your local machine, so does not require connecting to a service. \n",
    "\n",
    "This tutorial will cover the basics of creating an agent, interacting with an agent, and understanding the agent's state and memories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2737c9-ecf1-4eea-a92a-f358d68a66b6",
   "metadata": {},
   "source": [
    "## Step 0: Install the `letta` package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba135418-96fb-4000-a04e-f0b80d887358",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U letta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e913e-3ba6-40dd-99e8-875c8e38514e",
   "metadata": {},
   "source": [
    "We'll also import a helper function to print out messages from agents in a nice format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b393d2f-a174-45fe-a91b-50f1c9a4cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import json\n",
    "import re\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def nb_print(messages):\n",
    "    html_output = \"\"\"\n",
    "    <style>\n",
    "        .message-container {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 20px auto;\n",
    "            background-color: #1e1e1e;\n",
    "            border-radius: 8px;\n",
    "            overflow: hidden;\n",
    "            color: #d4d4d4;\n",
    "        }\n",
    "        .message {\n",
    "            padding: 10px 15px;\n",
    "            border-bottom: 1px solid #3a3a3a;\n",
    "        }\n",
    "        .message:last-child {\n",
    "            border-bottom: none;\n",
    "        }\n",
    "        .title {\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 5px;\n",
    "            color: #ffffff;\n",
    "            text-transform: uppercase;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "        .content {\n",
    "            background-color: #2d2d2d;\n",
    "            border-radius: 4px;\n",
    "            padding: 5px 10px;\n",
    "            font-family: 'Consolas', 'Courier New', monospace;\n",
    "            white-space: pre-wrap;\n",
    "        }\n",
    "        .status-line {\n",
    "            margin-bottom: 5px;\n",
    "            color: #d4d4d4;\n",
    "        }\n",
    "        .function-name { color: #569cd6; }\n",
    "        .json-key { color: #9cdcfe; }\n",
    "        .json-string { color: #ce9178; }\n",
    "        .json-number { color: #b5cea8; }\n",
    "        .json-boolean { color: #569cd6; }\n",
    "        .internal-monologue { font-style: italic; }\n",
    "    </style>\n",
    "    <div class=\"message-container\">\n",
    "    \"\"\"\n",
    "\n",
    "    for msg in messages:\n",
    "        content = get_formatted_content(msg)\n",
    "\n",
    "        # don't print empty function returns\n",
    "        if msg.message_type == \"function_return\":\n",
    "            return_data = json.loads(msg.function_return)\n",
    "            if \"message\" in return_data and return_data[\"message\"] == \"None\":\n",
    "                continue\n",
    "\n",
    "        title = msg.message_type.replace(\"_\", \" \").upper()\n",
    "        html_output += f\"\"\"\n",
    "        <div class=\"message\">\n",
    "            <div class=\"title\">{title}</div>\n",
    "            {content}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    html_output += \"</div>\"\n",
    "    display(HTML(html_output))\n",
    "\n",
    "\n",
    "def get_formatted_content(msg):\n",
    "    if msg.message_type == \"internal_monologue\":\n",
    "        return f'<div class=\"content\"><span class=\"internal-monologue\">{html.escape(msg.internal_monologue)}</span></div>'\n",
    "    elif msg.message_type == \"function_call\":\n",
    "        args = format_json(msg.function_call.arguments)\n",
    "        return f'<div class=\"content\"><span class=\"function-name\">{html.escape(msg.function_call.name)}</span>({args})</div>'\n",
    "    elif msg.message_type == \"function_return\":\n",
    "\n",
    "        return_value = format_json(msg.function_return)\n",
    "        # return f'<div class=\"status-line\">Status: {html.escape(msg.status)}</div><div class=\"content\">{return_value}</div>'\n",
    "        return f'<div class=\"content\">{return_value}</div>'\n",
    "    elif msg.message_type == \"user_message\":\n",
    "        if is_json(msg.message):\n",
    "            return f'<div class=\"content\">{format_json(msg.message)}</div>'\n",
    "        else:\n",
    "            return f'<div class=\"content\">{html.escape(msg.message)}</div>'\n",
    "    elif msg.message_type in [\"assistant_message\", \"system_message\"]:\n",
    "        return f'<div class=\"content\">{html.escape(msg.message)}</div>'\n",
    "    else:\n",
    "        return f'<div class=\"content\">{html.escape(str(msg))}</div>'\n",
    "\n",
    "\n",
    "def is_json(string):\n",
    "    try:\n",
    "        json.loads(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def format_json(json_str):\n",
    "    try:\n",
    "        parsed = json.loads(json_str)\n",
    "        formatted = json.dumps(parsed, indent=2, ensure_ascii=False)\n",
    "        formatted = formatted.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "        formatted = formatted.replace(\"\\n\", \"<br>\").replace(\"  \", \"&nbsp;&nbsp;\")\n",
    "        formatted = re.sub(r'(\".*?\"):', r'<span class=\"json-key\">\\1</span>:', formatted)\n",
    "        formatted = re.sub(r': (\".*?\")', r': <span class=\"json-string\">\\1</span>', formatted)\n",
    "        formatted = re.sub(r\": (\\d+)\", r': <span class=\"json-number\">\\1</span>', formatted)\n",
    "        formatted = re.sub(r\": (true|false)\", r': <span class=\"json-boolean\">\\1</span>', formatted)\n",
    "        return formatted\n",
    "    except json.JSONDecodeError:\n",
    "        return html.escape(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7105f-2b94-4b67-9088-e4d3f9304e2c",
   "metadata": {},
   "source": [
    "## Step 1: Create a `LocalClient` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc14de-feed-43be-be02-4a57709debb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta import LocalClient\n",
    "\n",
    "client = LocalClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1d1c4-743b-4aee-a8e0-7d89cd55f887",
   "metadata": {},
   "source": [
    "### Configuring client defaults \n",
    "Agents in Letta are model agnostic, so they can connect to different model backends (you can even switch model backends for an existing agents). For this tutorial, we'll set a client default config so that all agents are created with the free letta model endpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd03b25-f9db-4e33-af35-43fd897862b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta import LLMConfig, EmbeddingConfig\n",
    "\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"letta\")) \n",
    "client.set_default_embedding_config(EmbeddingConfig.default_config(\"letta\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f271813-baad-4dea-9de9-f6cb63d987ff",
   "metadata": {},
   "source": [
    "## Step 2: Creating an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a8a4c-a4c1-4dde-b4ef-f1e9f53994c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"my_agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9b042-98a1-4768-bdc3-15cf95dbb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "\n",
    "agent_state = client.create_agent(\n",
    "    name=agent_name, \n",
    "    memory=ChatMemory(\n",
    "        human=\"My name is Sarah\", \n",
    "        persona=\"You are a helpful assistant that loves emojis\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b03089-9aed-4e04-a1f7-75e77e100198",
   "metadata": {},
   "source": [
    "### Messaging the agent \n",
    "Now we can message the agent! This agent will have memories about both itself and the human (you). When we send a message to the agent, we will get back a list of messages from the agents. \n",
    "\n",
    "Letta agents have some unique characteristics that allow them to have more advanced reasoning. Notice how: \n",
    "* The agent generates *inner thoughts* to think before it acts\n",
    "* Messages to the user are generated via a `send_message` tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f931c-29a5-4f2b-8744-1765c213aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message=\"hello!\", \n",
    "    role=\"user\" \n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbad14d-614b-4f67-adea-056a13562fae",
   "metadata": {},
   "source": [
    "## Step 3: Understanding agent state \n",
    "Agents are essentailly multi-step reasoning programs which make multiple call to an LLM. Letta manages what is passed to the context window in reach reasoning step. The context window includes: \n",
    "* The *system prompt* to define the agent's behavior \n",
    "* The set of *tools* the agent has access to \n",
    "* The agent's *core memory* (i.e. in-context memory)\n",
    "* A summary of it's *archival memory* \n",
    "* A summary of it's *recall memory* \n",
    "* An in-context message queue\n",
    "\n",
    "In this section, we'll look at the current state of the agent to understand exactly what is being passed to the context window. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02ea54-1cf1-4253-9ea0-8401b4af1224",
   "metadata": {},
   "source": [
    "### System Prompt \n",
    "The system prompt defines the behavior of the agent. Unlike the memory, the system prompt is not editable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc3258-2218-43e9-9559-252e95845572",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_state.system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713ce65-1655-4ac1-a6ae-d27f4ca72683",
   "metadata": {},
   "source": [
    "### Tools \n",
    "The agent has access to a set of tools. Each tool is stored in a database, so it can be loaded and executed by the server. Letta also includes a set of default memory management tools, as well as the `send_message` tool to communicate with the human. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b05995-4572-4a24-8e67-9071c5101b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_state.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf489a5-5e16-4739-8114-d3abf501f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_tool(client.get_tool_id('send_message'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb258732-dbb7-4f0e-a895-a440ec09256b",
   "metadata": {},
   "source": [
    "### Core memory \n",
    "The core memory is the part of memory that is places *in-context*. Core memory is divided into multiple blocks, which each have a `label` and `limit` (the number of characters allocated to storing memories in that block). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c1a61-b39e-410d-b049-2a1719af3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = client.get_core_memory(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf336c-de93-449d-ab4e-440ccfbbc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a379a96-4d48-4727-82ea-53a75c38ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.get_block('human')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa085d-1c28-4a4b-88bb-3cc299089eb0",
   "metadata": {},
   "source": [
    "You can see how the memory is presented in the context window with `.compile()`, which uses the `prompt_template` to template the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883a5ac-204b-490e-b887-9058dc3ce81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0997067-c3f3-46f0-83d3-7a91f472fd25",
   "metadata": {},
   "source": [
    "### Archival & Recall memory summaries\n",
    "The agent also has access to external memories (stored in a database). There are two types of external memory: \n",
    "* *Archival memory*: Memories stored in a vector database that are either saved by the agent itself, or loaded in by the user\n",
    "* *Recall memory*: The full conversational history of the agent\n",
    "\n",
    "Both of these memories stores can be queried by the agent for RAG. To ensure the agent knows that these external memories stores may have relevant information, the context window contains a summary of the number of rows in both archival and recall memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57b72e-60a4-475c-b157-bf4f2253bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_archival_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf5103-412b-4dbd-a3e1-1707def174a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_recall_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbff152-946e-4e64-8dcc-7d527cab0175",
   "metadata": {},
   "source": [
    "You can also directly query the full conversational history: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3de44-662f-444d-b3cc-45f51a4c12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_messages(agent_state.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33971ab-5f9d-4228-9c79-8e3d12d9dbbd",
   "metadata": {},
   "source": [
    "## Section 4: Modifying core memory \n",
    "The core memory can adapt over time as new information is provided about the human (or about the agent itself). Letta agents have the ability to adapt their memory by modifying their context window.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44574fda-f279-4ea1-9018-9d110b56f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"My name is actually Charles\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488eb05b-996a-4beb-b91f-7c2135963c1d",
   "metadata": {},
   "source": [
    "Now we can see the updated core memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cbbab-df45-4a96-8cb8-45f79e1c67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_core_memory(agent_state.id).get_block(\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c352bbd-46df-490d-8667-ee16d9ce65a5",
   "metadata": {},
   "source": [
    "## Section 5: Modifying archival memory \n",
    "The agent can also use the archival memory store to save memories. Since archival memory is a vector DB, we can also directly insert in memories - this can be useful if you have external data sources that you want the agent to be able to connect to via memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790735ce-5841-47c7-b9e6-b687e18c096c",
   "metadata": {},
   "source": [
    "First, lets trigger the agent to write an archival memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cba5a-dbe1-43eb-b57f-9939a6d55441",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"Save the information that 'bob loves cats' to archival\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690bcea-0af5-43db-a024-e0ecbdce5156",
   "metadata": {},
   "source": [
    "We can also insert an archival memory manually: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474530-2168-4d1c-b165-2a3c47dac571",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.insert_archival_memory(\n",
    "    agent_state.id, \n",
    "    \"Bob's loves boston terriers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf8cde-fc36-43a7-aa23-6cc26f1c829b",
   "metadata": {},
   "source": [
    "Now, we can have the agent run RAG to answer a specific question: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228d992-24c6-4d9a-887a-f60d3beedca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"What animals do I like? Search archival.\"\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9a5c9-4e3b-4b8e-8b8e-5f1c9a4cb9d",
   "metadata": {},
   "source": [
    "## Section 6: Demonstrating Memory Categorization and Prioritization\n",
    "In this section, we will demonstrate how to categorize and prioritize memories using the new memory management system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9a5c9-4e3b-4b8e-8b8e-5f1c9a4cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import Memory, MemoryManager\n",
    "\n",
    "memory_manager = MemoryManager()\n",
    "\n",
    "memory1 = Memory(\"Learned about AI\", 10)\n",
    "memory2 = Memory(\"Had lunch\", 5)\n",
    "memory3 = Memory(\"Went for a walk\", 7)\n",
    "\n",
    "memory_manager.add_memory(memory1, \"short_term\")\n",
    "memory_manager.add_memory(memory2, \"long_term\")\n",
    "memory_manager.add_memory(memory3, \"episodic\")\n",
    "\n",
    "memory_manager.prioritize_memories()\n",
    "print(\"Prioritized Memories:\", memory_manager.get_memories(\"short_term\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106a5c9-4e3b-4b8e-8b8e-5f1c9a4cb9d",
   "metadata": {},
   "source": [
    "## Section 7: Demonstrating Memory Decay Mechanism\n",
    "In this section, we will demonstrate how the decay mechanism works to gradually forget less important memories over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106a5c9-4e3b-4b8e-8b8e-5f1c9a4cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "memory_manager.decay_memories()\n",
    "print(\"Memories after decay:\", memory_manager.get_memories(\"short_term\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "letta-tutorial",
   "language": "python",
   "name": "letta-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
